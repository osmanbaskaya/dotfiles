_HiStOrY_V2_
import\040datetime
datetime.datetime.now()
d\040=\040datetime.datetime.now()
d
d.now()
dir(d)
d.tiemstamp()
d.tiemstamp
d.timestamp
d.timestamp()
s
ls
import\040subprocess
subprocess.run("ls")
subprocess.run("ls",\040capture_output)
subprocess.run("ls",\040capture_output=True)
a\040=\040subprocess.run("ls",\040capture_output=True)
a
a['stdout']
a.stdout
a.stdout.encode('utf8')
a.stdout.decode('utf8')
import\040os
os.system("gcloud")
import\040os
os.system("gcloud")
import\040homemade
homemade.clients
import\040homemade
homemade.__version__
import\040homemade
homemade.clients
from\040homemade\040import\040clients
dir(clients)
ls
import\040homemade_common
import\040time
time.perf_counter()
import\040pathlib
from\040pathlib\040import\040Path
Path(__file__)
import\040base64
base64.b64decode
import\040random
random.choice(3)
random.choice([1,5,10])
fg
import\040cloudpickle
cloudpickle.load(open('cache.pkl))
cloudpickle.load(open('cache.pkl)))
cloudpickle.load(open('cache.pkl'))
cloudpickle.load(open('cache.pkl',\040'rb))
cloudpickle.load(open('cache.pkl',\040'rb'))
m\040=\040cloudpickle.load(open('cache.pkl',\040'rb'))
m
type(m
)
m.add_to_cache(1)
m.add_to_cache(1,\040'hede')
m.add_to_cache(1,\040source='hede')
m\040=\040cloudpickle.load(open('cache.pkl',\040'rb'))
import\040cloudpickle
m\040=\040cloudpickle.load(open('cache.pkl',\040'rb'))
m.add_to_cache(1,\040source='hede')
m
m[3]\040=\0401
m
m[31]\040=\0401
m
import\040eksi_parser
import\040eksi_crawler
from\040eksi_crawler.parser\040import\040EksiParser()
from\040eksi_crawler.parser\040import\040EksiParser
EksiParser()
a\040=\040EksiParser()
a.eksi_client
a.eksi_client.TOPIC_URL
a.eksi_client.ENTRY_URL
from\040eksi_crawler.parser\040import\040EksiPArser
from\040eksi_crawler.parser\040import\040EksiParser
EksiParser.parse_entry()
EksiParser.parse_entry('asfd)
EksiParser.parse_entry('asfd')
from\040eksi_crawler.parser\040import\040EksiParser()
from\040eksi_crawler.parser\040import\040EksiParser
EksiParser()
s\040=\040socket.socket(socket.AF_INET,\040socket.SOCK_STREAM)
import\040socket
s\040=\040socket.socket(socket.AF_INET,\040socket.SOCK_STREAM)
s
s.connet_ex(8000)
s.connect_ex(8000)
s.connect_ex(("127.0.0.1",\0408000))
s.connect_ex(("127.0.0.1",\0408001))
s.connect_ex(("127.0.0.1",\0408002))
s.connect_ex(("127.0.0.1",\0406379))
s.connect_ex(("127.0.0.1",\0406373))
s.connect_ex(("127.0.0.1",\040637223))
s.connect_ex(("127.0.0.1",\04063723))
s.connect_ex(("127.0.0.1",\04080))
s.connect_ex(("127.0.0.1",\040801))
s.connect_ex(("127.0.0.1",\040"291"))
s.connect_ex(("127.0.0.1",\0408000))
s.connect_ex(("127.0.0.1",\0408001))
s.connect_ex(("127.0.0.1",\0408000))
s.connect_ex(("127.0.0.1",\0408005))
s.connect_ex(("127.0.0.1",\0408080))
s.connect_ex(("127.0.0.1",\0408085))
s.settimeout(1)
s.connect_ex(("127.0.0.1",\0408085))
s.connect_ex(("127.0.0.1",\0408000))
import\040socket
s.connect_ex(("127.0.0.1",\0408000))
s\040=\040socket.socket(socket.AF_INET,\040socket.SOCK_STREAM)
s.settimeout(1)
s.connect_ex(("127.0.0.1",\0408000))
import\040psutil
8000\040in\040[i.laddr.port\040for\040i\040in\040psutil.net_connections()]
import\040eksi_crawler.config
eksi_crawler.config.settings
from\040from\040eksi_crawler.utils\040import\040configure_logger,\040publish_unprocessed_paths
from\040eksi_crawler.utils\040import\040configure_logger,\040publish_unprocessed_paths
import\040itertools
import\040json
json.load(open('small-data.json'))
import\040json
json.load(open('small-data.json'))
fg
json.load(open('small-data.json'))
fg
import\040json
json.load(open('small-data.json'))
a\040=\040json.load(open('small-data.json'))
a.keys()
from\040comcrawl\040import\040IndexClient
client\040=\040IndexClient(['2020-10',\040'2020-16'])
resp\040=\040client.search('https://www.reddit.com/r/dataisbeautiful/*',\040threads=1)
respo
resp
client.results
client.results[0]
resp\040=\040client.search('https://eksisozluk.com/thorn-pyros--1435484',\040threads=1)
client.results
resp\040=\040client.search('https://eksisozluk.com/thorn-pyros*',\040threads=1)
client.search('https://eksisozluk.com/thorn-pyros*',\040threads=1)
client.results
client.search('https://eksisozluk.com/*',\040threads=1)
client.results
len(client.results)
client.help
client.search('*://eksisozluk.com/*',\040threads=1)
len(client.results)
client.search('*eksisozluk.com/*',\040threads=1)
len(client.results)
client.search('https?://eksisozluk.com/*',\040threads=1)
len(client.results)
client.search('https://eksisozluk.com/*',\040threads=1)
len(client.results)
client.search('http://eksisozluk.com/*',\040threads=1)
len(client.results)
client.search('https://en.wikipedia.org/wiki/*',\040threads=1)
len(client.results)
client\040=\040IndexClient(["2019-51",\040"2019-47"])
client.search("reddit.com/r/MachineLearning/*")
len(client.results)
client.search('https://en.wikipedia.org/wiki/*',\040threads=1)
len(client.results)
client\040=\040IndexClient([f"2019-{week}"\040for\040week\040in\040range(20])
client\040=\040IndexClient([f"2019-{week}"\040for\040week\040in\040range(1,20)])
client
client.indexes
client.search('https://en.wikipedia.org/wiki/*',\040threads=1)
client\040=\040IndexClient([f"2019-{week}"\040for\040week\040in\040range(10,20)])
client.indexes
client.search('https://en.wikipedia.org/wiki/*',\040threads=1)
len(client.results)
import\040pandas\040as\040pd
pd.read_excel("https://docs.google.com/spreadsheets/d/1mZSqW_X_KuQQdGhH7oAn3-MATyfePLlYYmOgE-mB_9Q/export?format=xlsx&gid=")
pd.read_excel(url)
url\040=\040https://docs.google.com/spreadsheets/d/1mZSqW_X_KuQQdGhH7oAn3-MATyfePLlYYmOgE-mB_9Q/edit#gid=0
url\040=\040"https://docs.google.com/spreadsheets/d/1mZSqW_X_KuQQdGhH7oAn3-MATyfePLlYYmOgE-mB_9Q/edit#gid=0"
pd.read_excel(url)
pd.read_excel(url,\040'xlsx')
pd.read_excel(url,\040'xls')
pd.read_excel(url,\040engine='xlsx')
pd.read_excel(url,\040engine='openpyxl')
import\040pandas\040as\040pd
url\040=\040"https://docs.google.com/spreadsheets/d/1mZSqW_X_KuQQdGhH7oAn3-MATyfePLlYYmOgE-mB_9Q/edit#gid=0"
pd.read_excel(url,\040engine='openpyxl')
url\040=\040"https://docs.google.com/spreadsheets/d/1mZSqW_X_KuQQdGhH7oAn3-MATyfePLlYYmOgE-mB_9Q/export?format=xlsx&gid="
pd.read_excel(url,\040engine='openpyxl')
url\040=\040"https://docs.google.com/spreadsheets/d/1mZSqW_X_KuQQdGhH7oAn3-MATyfePLlYYmOgE-mB_9Q/export?format=xlsx&gid=0"
pd.read_excel(url,\040engine='openpyxl')
pd.read_excel(url)
import\040PAth
import\040Path
from\040pathlib\040import\040Path
Path('/a/b/c/d/e/f.py')
a\040=\040Path('/a/b/c/d/e/f.py')
a
a.parent[0]
a.parents[0]
a.parents[1]
a.parents[2]
a.parents[3]
a.parents[4]
a.parents[3]
client\040=\040storage.Client.create_anonymous_client()
bucket\040=\040client.bucket('publically_listable_bucket')
blobs\040=\040list(bucket.list_blobs())
from\040google.cloud\040import\040storage
client\040=\040storage.Client.create_anonymous_client()
bucket\040=\040client.bucket('publically_listable_bucket')
blobs\040=\040list(bucket.list_blobs())
bucket\040=\040client.bucket('inflation-in-turkey')
bucket.list_blobs()
list(bucket.list_blobs())
blobs\040=\040list(bucket.list_blobs())
bucket\040=\040client.bucket('inflation-in-turkeyasdf')
blobs\040=\040list(bucket.list_blobs())
bucket\040=\040client.bucket('inflation-in-turkey')
import\040requests
requests.get("https://www.amazon.com/dp/B077L6XDNP?almBrandId=VUZHIFdob2xlIEZvb2Rz")
a\040-\040requests.get("https://www.amazon.com/dp/B077L6XDNP?almBrandId=VUZHIFdob2xlIEZvb2Rz")
requests.get("https://openai.com/")
import\040requests
requests.get("https://openai.com/")
import\040difflib
1700\040/\04016
1700\040/\0408
0.01\040*\0403000
a\040=\040"Feedback
content-length-too-long,feedback-to-suggestions,accountability,app-over-sms
conversational
partner-usage-asymmetry,answer-privacy,time-to-send,conversational
knowledge-personalization
time-to-send,message-frequency,gamification
message-frequency
message-frequency,date-recommendations
date-recommendations
knowledge-personalization
scoring-framework,ai-for-privacy,gamification,date-recommendations,gift-suggestions,affiliate-marketing,onboarding-tags,knowledge-personalization
partner-usage-asymmetry,content-length-too-long,feedback-to-suggestions
message-frequency
partner-usage-asymmetry,feedback-to-suggestions,knowledge-personalization
message-frequency
sms-over-app,time-to-send
time-to-send
stronger-onboarding-ux
feedback-to-suggestions,knowledge-personalization,ai-for-privacy,stronger-onboarding-ux
knowledge-personalization,date-recommendations,ai-for-privacy,gamification,time-to-send,onboarding-tags
partner-usage-asymmetry,message-frequency,date-recommendations
ai-for-privacy
gamification,time-to-send,date-recommendations,knowledge-personalization,message-frequency
knowledge-personalization,message-frequency,onboarding-tags,user-stats,ai-for-privacy,app-over-sms
knowledge-personalization,message-frequency
message-frequency
essage-fre
ssage-fre
quency
iza
za
cy
re
quency
ization,message-frequency
onboarding-tags,user-stats,ai-for-privacy,
nboarding-tags,user-stats,ai-for-privacy,
onboarding-tags,user-stats,ai-for-privacy,app-over-sms
nboarding-tags,user-stats,ai-for-privacy,app-over-sms
tags,u
ags,u
ng-tags,user-stats,ai-for-privacy,app-over-sms
tags,user-stats,ai-for-privacy,app
pd
a\040=\040open("/Users/obaskaya/Documents/Maia\134\040_\134\040SMS\134\040Pilot\134\040Program\134\040\134(Responses\134)\134\040-\134\040Feedback\134\040WIP.tsv").readlines()
lines\040=\040open("/Users/obaskaya/Documents/maia.tsv").read().strip().splitlines()
lines
lines[0]
lines[1]
lines[2]
lines[1]
lines[1].split('\134t')
lines[1].rsplit('\134t',\0401)
lines[1].rsplit('\134t',\0401)[-1]
lines[1].rsplit('\134t',\0401)[-1].split(',')
[line.rsplit('\134t',\0401)[-1].split(',')\040for\040line\040in\040lines[1:]
a\040=\040[line.rsplit('\134t',\0401)[-1].split(',')\040for\040line\040in\040lines[1:]]
a
values\040=\040[line.rsplit('\134t',\0401)[-1].split(',')\040for\040line\040in\040lines[1:]]
values
list(chain(*values))
from\040itertools\040import\040chain
list(chain(*values))
[line\040if\040len(line)\040!=\0400\040for\040line\040in\040list(chain(*values))]
line
[line\040for\040line\040in\040list(chain(*values))]
[line\040for\040line\040in\040list(chain(*values))\040if\040line\040!=\040'']
values\040=\040[line\040for\040line\040in\040list(chain(*values))\040if\040line\040!=\040'']
values
print("\134n".values())
print("\134n".join(values))
